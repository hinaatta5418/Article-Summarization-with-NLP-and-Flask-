{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdvvmVSzpGIC"
   },
   "source": [
    "# **Downloading Resources**\n",
    "**Stopwords:** Stopwords are common words in a language (e.g., \"the\", \"is\", \"and\") that often occur frequently but do not carry much meaning. In many NLP tasks, including text classification, sentiment analysis, and information retrieval, removing stopwords can improve performance by reducing noise and focusing on the more informative words in the text.\n",
    "\n",
    "**WordNet:** WordNet is a lexical database of English words that provides semantic relationships between words, such as synonyms, hypernyms, hyponyms, and meronyms. WordNet is often used in various NLP tasks for tasks like word sense disambiguation, semantic similarity measurement, and lemmatization. In the preprocessing step, lemmatization is used to reduce words to their base or dictionary form, which helps in standardizing words and improving text analysis accuracy.\n",
    "\n",
    "**Punkt Tokenizer:** Punkt is a pre-trained unsupervised machine learning model for sentence tokenization, which means it is trained to segment text into sentences. Sentence tokenization is essential for many NLP tasks, including text summarization, machine translation, and information extraction. Punkt tokenizer accurately identifies sentence boundaries even in complex cases like abbreviations, which is crucial for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYPtkMSZnMup",
    "outputId": "397243d3-a3f8-4574-fa8a-316f3cea81c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wA3pGOTnYC5",
    "outputId": "fea32c1c-9c8b-466a-aa80-7dcaa494302c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pn3To6-FnkZg",
    "outputId": "a7198765-6fe8-42fe-f07c-e77d3dad3dd9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERBxusr7qXSg"
   },
   "source": [
    "# **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXx7Xh4jn2nE",
    "outputId": "514798ad-f21f-440e-e5a2-08a0fb1c01e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                URL Link Source Page  \\\n",
      "0  https://edition.cnn.com/2024/04/23/health/pick...   \n",
      "1  https://edition.cnn.com/2024/04/22/health/plas...   \n",
      "2  https://edition.cnn.com/2024/04/19/health/joy-...   \n",
      "\n",
      "                               Published Date  Article Writer  \\\n",
      "0   Published 1:16 PM EDT, Mon April 22, 2024  Kristen Rogers   \n",
      "1  Published 10:53 AM EDT, Mon April 22, 2024  Sandee LaMotte   \n",
      "2  Published 12:02 PM EDT, Fri April 19, 2024     Andrea Kane   \n",
      "\n",
      "                                     Article Heading  \\\n",
      "0  3 in 5 families are short-order cooks for pick...   \n",
      "1  Which foods have the most plastics? You may be...   \n",
      "2                  5 ways to add joy into your meals   \n",
      "\n",
      "                                            Article   \n",
      "0   Each of Tara Marklin’s three sons have vastly...  \n",
      "1  “How much plastic will you have for dinner, si...  \n",
      "2  In this season of the podcast Chasing Life Wit...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"sample_data/FinalFile.csv\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0elmtwJrGFS"
   },
   "source": [
    "# Drop rows with missing values in the 'Article' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyorTmv8n6mC"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['Article '], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VwKbHRGrMK0"
   },
   "source": [
    "# Preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLOdSH2RrVio"
   },
   "source": [
    "# 1. Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2_E5uMsn-yA",
    "outputId": "30d49bc0-dbdf-4035-99e1-84ded74736ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                URL Link Source Page  \\\n",
      "0  https://edition.cnn.com/2024/04/23/health/pick...   \n",
      "1  https://edition.cnn.com/2024/04/22/health/plas...   \n",
      "2  https://edition.cnn.com/2024/04/19/health/joy-...   \n",
      "\n",
      "                               Published Date  Article Writer  \\\n",
      "0   Published 1:16 PM EDT, Mon April 22, 2024  Kristen Rogers   \n",
      "1  Published 10:53 AM EDT, Mon April 22, 2024  Sandee LaMotte   \n",
      "2  Published 12:02 PM EDT, Fri April 19, 2024     Andrea Kane   \n",
      "\n",
      "                                     Article Heading  \\\n",
      "0  3 in 5 families are short-order cooks for pick...   \n",
      "1  Which foods have the most plastics? You may be...   \n",
      "2                  5 ways to add joy into your meals   \n",
      "\n",
      "                                            Article   \n",
      "0   each of tara marklin’s three sons have vastly...  \n",
      "1  “how much plastic will you have for dinner, si...  \n",
      "2  in this season of the podcast chasing life wit...  \n"
     ]
    }
   ],
   "source": [
    "df['Article '] = df['Article '].str.lower()\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBdXlAhXrb_r"
   },
   "source": [
    "# 2. Remove unwanted characters like punctuation, special symbols, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1W_e6saAoGwW",
    "outputId": "51f6fb45-8311-462e-c510-df07fb3b1fe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                URL Link Source Page  \\\n",
      "0  https://edition.cnn.com/2024/04/23/health/pick...   \n",
      "1  https://edition.cnn.com/2024/04/22/health/plas...   \n",
      "2  https://edition.cnn.com/2024/04/19/health/joy-...   \n",
      "\n",
      "                               Published Date  Article Writer  \\\n",
      "0   Published 1:16 PM EDT, Mon April 22, 2024  Kristen Rogers   \n",
      "1  Published 10:53 AM EDT, Mon April 22, 2024  Sandee LaMotte   \n",
      "2  Published 12:02 PM EDT, Fri April 19, 2024     Andrea Kane   \n",
      "\n",
      "                                     Article Heading  \\\n",
      "0  3 in 5 families are short-order cooks for pick...   \n",
      "1  Which foods have the most plastics? You may be...   \n",
      "2                  5 ways to add joy into your meals   \n",
      "\n",
      "                                            Article   \n",
      "0   each of tara marklins three sons have vastly ...  \n",
      "1  how much plastic will you have for dinner sir ...  \n",
      "2  in this season of the podcast chasing life wit...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "df['Article '] = df['Article '].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))  # Handle NaN values by converting to string\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oVMgyutrhQB"
   },
   "source": [
    "# 3. Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmOO7tzOoJKz",
    "outputId": "c68ac188-df10-48d2-c2fc-b7fe61e59f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                URL Link Source Page  \\\n",
      "0  https://edition.cnn.com/2024/04/23/health/pick...   \n",
      "1  https://edition.cnn.com/2024/04/22/health/plas...   \n",
      "2  https://edition.cnn.com/2024/04/19/health/joy-...   \n",
      "\n",
      "                               Published Date  Article Writer  \\\n",
      "0   Published 1:16 PM EDT, Mon April 22, 2024  Kristen Rogers   \n",
      "1  Published 10:53 AM EDT, Mon April 22, 2024  Sandee LaMotte   \n",
      "2  Published 12:02 PM EDT, Fri April 19, 2024     Andrea Kane   \n",
      "\n",
      "                                     Article Heading  \\\n",
      "0  3 in 5 families are short-order cooks for pick...   \n",
      "1  Which foods have the most plastics? You may be...   \n",
      "2                  5 ways to add joy into your meals   \n",
      "\n",
      "                                            Article   \n",
      "0  [each, of, tara, marklins, three, sons, have, ...  \n",
      "1  [how, much, plastic, will, you, have, for, din...  \n",
      "2  [in, this, season, of, the, podcast, chasing, ...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df['Article '] = df['Article '].apply(word_tokenize)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3W--p7rlVi"
   },
   "source": [
    "# 4. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuqFOngUoLZz",
    "outputId": "d3850e06-a6aa-48fa-8ae9-8e76140f3018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                URL Link Source Page  \\\n",
      "0  https://edition.cnn.com/2024/04/23/health/pick...   \n",
      "1  https://edition.cnn.com/2024/04/22/health/plas...   \n",
      "2  https://edition.cnn.com/2024/04/19/health/joy-...   \n",
      "\n",
      "                               Published Date  Article Writer  \\\n",
      "0   Published 1:16 PM EDT, Mon April 22, 2024  Kristen Rogers   \n",
      "1  Published 10:53 AM EDT, Mon April 22, 2024  Sandee LaMotte   \n",
      "2  Published 12:02 PM EDT, Fri April 19, 2024     Andrea Kane   \n",
      "\n",
      "                                     Article Heading  \\\n",
      "0  3 in 5 families are short-order cooks for pick...   \n",
      "1  Which foods have the most plastics? You may be...   \n",
      "2                  5 ways to add joy into your meals   \n",
      "\n",
      "                                            Article   \n",
      "0  [tara, marklins, three, sons, vastly, differen...  \n",
      "1  [much, plastic, dinner, sir, maam, may, seem, ...  \n",
      "2  [season, podcast, chasing, life, dr, sanjay, g...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Article '] = df['Article '].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78qwzJ9mrpEW"
   },
   "source": [
    "# 5. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXFJNe6UoMz8",
    "outputId": "e57d0e23-ffc0-49ad-beef-0a626146be22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                URL Link Source Page  \\\n",
      "0  https://edition.cnn.com/2024/04/23/health/pick...   \n",
      "1  https://edition.cnn.com/2024/04/22/health/plas...   \n",
      "2  https://edition.cnn.com/2024/04/19/health/joy-...   \n",
      "\n",
      "                               Published Date  Article Writer  \\\n",
      "0   Published 1:16 PM EDT, Mon April 22, 2024  Kristen Rogers   \n",
      "1  Published 10:53 AM EDT, Mon April 22, 2024  Sandee LaMotte   \n",
      "2  Published 12:02 PM EDT, Fri April 19, 2024     Andrea Kane   \n",
      "\n",
      "                                     Article Heading  \\\n",
      "0  3 in 5 families are short-order cooks for pick...   \n",
      "1  Which foods have the most plastics? You may be...   \n",
      "2                  5 ways to add joy into your meals   \n",
      "\n",
      "                                            Article   \n",
      "0  [tara, marklins, three, son, vastly, different...  \n",
      "1  [much, plastic, dinner, sir, maam, may, seem, ...  \n",
      "2  [season, podcast, chasing, life, dr, sanjay, g...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['Article '] = df['Article '].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBzeli8truB9"
   },
   "source": [
    "# Display the preprocessed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hR0ICbBBoOTb",
    "outputId": "dae31fb9-7f1f-4bfd-832f-b42658d94d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                URL Link Source Page  \\\n",
      "0  https://edition.cnn.com/2024/04/23/health/pick...   \n",
      "1  https://edition.cnn.com/2024/04/22/health/plas...   \n",
      "2  https://edition.cnn.com/2024/04/19/health/joy-...   \n",
      "\n",
      "                               Published Date  Article Writer  \\\n",
      "0   Published 1:16 PM EDT, Mon April 22, 2024  Kristen Rogers   \n",
      "1  Published 10:53 AM EDT, Mon April 22, 2024  Sandee LaMotte   \n",
      "2  Published 12:02 PM EDT, Fri April 19, 2024     Andrea Kane   \n",
      "\n",
      "                                     Article Heading  \\\n",
      "0  3 in 5 families are short-order cooks for pick...   \n",
      "1  Which foods have the most plastics? You may be...   \n",
      "2                  5 ways to add joy into your meals   \n",
      "\n",
      "                                            Article   \n",
      "0  [tara, marklins, three, son, vastly, different...  \n",
      "1  [much, plastic, dinner, sir, maam, may, seem, ...  \n",
      "2  [season, podcast, chasing, life, dr, sanjay, g...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89TEKegPsRlP"
   },
   "source": [
    "# Save the preprocessed DataFrame to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6uA6E5asNZR"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"preprocessed_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4SQlKLHsa-T"
   },
   "source": [
    "# **SUMMARY**\n",
    "The preprocessing steps performed above are common **text preprocessing techniques** used to clean and prepare textual data for natural language processing tasks. Here's a summary of each step:\n",
    "\n",
    "**Convert text to lowercase:** This step ensures consistency by converting all text to lowercase. It helps in treating words with the same characters but different cases as identical.\n",
    "\n",
    "**Remove unwanted characters:** Using regular expressions (re.sub()), special characters, punctuation, and other non-alphanumeric characters are removed from the text. This step helps in eliminating noise from the text data.\n",
    "\n",
    "**Tokenization:** Tokenization is the process of breaking down a text into individual words or tokens. In the provided code, word_tokenize() from the NLTK library is used to tokenize the text.\n",
    "\n",
    "**Remove stop words:** Stop words are common words that typically do not carry significant meaning and are often removed from text data. Examples include \"the\", \"is\", \"and\", etc. By removing these words, we can focus on the more important words in the text. The NLTK library is used to obtain a set of stop words in English, and then these stop words are removed from the tokenized text.\n",
    "\n",
    "**Lemmatization:** Lemmatization reduces words to their base or root form, called a lemma. It helps in normalizing words so that different forms of the same word are treated as one. For example, \"running\", \"ran\", and \"runs\" all reduce to \"run\". The NLTK library is used for lemmatization in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viGzlkdDg-I_",
    "outputId": "86c1133a-729c-4050-b659-28423cd6fbe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njy7P8mWhN33",
    "outputId": "562388d1-9298-4ba9-e207-9b6b71d03260"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 129. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 150, but your input_length is only 146. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n",
      "Your max_length is set to 150, but your input_length is only 149. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=74)\n",
      "Your max_length is set to 150, but your input_length is only 149. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=74)\n",
      "Your max_length is set to 150, but your input_length is only 110. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n",
      "Your max_length is set to 150, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 150, but your input_length is only 143. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n",
      "Your max_length is set to 150, but your input_length is only 129. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 150, but your input_length is only 146. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n",
      "Your max_length is set to 150, but your input_length is only 144. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=72)\n",
      "Your max_length is set to 150, but your input_length is only 145. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=72)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                URL Link Source Page  \\\n",
      "0  https://edition.cnn.com/2024/04/23/health/pick...   \n",
      "1  https://edition.cnn.com/2024/04/22/health/plas...   \n",
      "2  https://edition.cnn.com/2024/04/19/health/joy-...   \n",
      "3  https://edition.cnn.com/2024/04/18/health/impo...   \n",
      "4  https://edition.cnn.com/2024/04/02/health/rest...   \n",
      "\n",
      "                               Published Date     Article Writer  \\\n",
      "0   Published 1:16 PM EDT, Mon April 22, 2024     Kristen Rogers   \n",
      "1  Published 10:53 AM EDT, Mon April 22, 2024     Sandee LaMotte   \n",
      "2  Published 12:02 PM EDT, Fri April 19, 2024        Andrea Kane   \n",
      "3  Published 12:40 PM EDT, Thu April 18, 2024     Sandee LaMotte   \n",
      "4  \\nPublished 1:49 PM EDT, Tue April 2, 2024  Madeline Holcombe   \n",
      "\n",
      "                                     Article Heading  \\\n",
      "0  3 in 5 families are short-order cooks for pick...   \n",
      "1  Which foods have the most plastics? You may be...   \n",
      "2                  5 ways to add joy into your meals   \n",
      "3  Fresh and frozen imported strawberries highly ...   \n",
      "4  3 questions you need to ask yourself about you...   \n",
      "\n",
      "                                            Article   \\\n",
      "0  tara marklins three son vastly different appro...   \n",
      "1  much plastic dinner sir maam may seem like lin...   \n",
      "2  season podcast chasing life dr sanjay gupta cn...   \n",
      "3  fresh frozen canned nonorganic fruit vegetable...   \n",
      "4  plenty reason many health professional dont wa...   \n",
      "\n",
      "                                             Summary  \n",
      "0  Family meal is the most important meal of the ...  \n",
      "1   ninety percent animal vegetable protein sampl...  \n",
      "2  Dr sanjay gupta cnns chief medical corresponde...  \n",
      "3  The highest level pesticide found produce impo...  \n",
      "4  Restrictive diet can encourage bingeing behavi...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the preprocessed data from the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"/content/preprocessed_data.csv\")\n",
    "\n",
    "# Convert token list back to text\n",
    "df['Article '] = df['Article '].apply(lambda tokens: ' '.join(eval(tokens)))\n",
    "\n",
    "# Initialize the summarization pipeline with a specific model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Function to summarize text with truncation\n",
    "def summarize_text(text, max_length=1024):\n",
    "    # Truncate the text if it exceeds the model's maximum input length\n",
    "    truncated_text = text[:max_length]\n",
    "    # Summarize the text with the pipeline\n",
    "    summary = summarizer(truncated_text, max_length=150, min_length=40, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Apply the summarization function to the 'Article' column\n",
    "df['Summary'] = df['Article '].apply(lambda x: summarize_text(x))\n",
    "\n",
    "# Save the DataFrame with the summaries to a new CSV file\n",
    "df.to_csv(\"summarized_articles.csv\", index=False)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2apKFi-Lnz2a"
   },
   "source": [
    "**Install Dependencies:** Ensure transformers and torch libraries are installed.\n",
    "\n",
    "**Load Preprocessed Data:** Load the preprocessed CSV file into a DataFrame.\n",
    "\n",
    "**Convert Tokens to Text:** Convert the token lists back into text strings using the join method.\n",
    "\n",
    "**Initialize Summarization Pipeline:** Use the facebook/bart-large-cnn model for summarization.\n",
    "\n",
    "**Summarize Text:** Define a function summarize_text to summarize the text. The function truncates the text if it exceeds the model's maximum input length (1024 tokens).\n",
    "\n",
    "**Apply Summarization:** Apply the summarization function to each article in the DataFrame.\n",
    "\n",
    "**Save Summarized Data:** Save the DataFrame with the summaries to a new CSV file.\n",
    "\n",
    "The eval function is used to convert the string representation of the list back to an actual list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEwtRJGtoJWI"
   },
   "source": [
    "# Modal used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q75uTUEtoIEn"
   },
   "source": [
    "The summarization pipeline from Hugging Face's transformers library uses pre-trained models for text summarization. By default, if you don't specify a particular model, the pipeline uses the facebook/bart-large-cnn model. This is a popular model for summarization tasks based on the BART (Bidirectional and Auto-Regressive Transformers) architecture, specifically fine-tuned on CNN/DailyMail dataset for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Path to your saved model directory\n",
    "saved_model_dir = \"C:\\\\Users\\\\hinaa\\\\Desktop\\\\Article_summarization\"\n",
    "\n",
    "# Convert the model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
